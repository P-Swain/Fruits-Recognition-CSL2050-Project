{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee3637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm  # for the progress bar\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f5f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Load Feature Vectors and Labels\n",
    "def loadFeaturesAndLabels(features_path):\n",
    "\n",
    "    features = [] # list to store the feature vectors\n",
    "    labels = [] # list to store the labels\n",
    "    \n",
    "    # checking if the path exists\n",
    "    if not os.path.exists(features_path):\n",
    "        raise ValueError(f\"Path {features_path} does not exist.\")\n",
    "    # checking if the path is a directory\n",
    "    if not os.path.isdir(features_path):\n",
    "        raise ValueError(f\"Path {features_path} is not a directory.\")\n",
    "    \n",
    "    # going through through the folders and load the features\n",
    "    for fruit_folder in tqdm(os.listdir(features_path), unit=\"folder\", desc=f\"Loading Features from {features_path}\"):\n",
    "\n",
    "        fruit_folder_path = os.path.join(features_path, fruit_folder) # creating complete path of the fruit folder\n",
    "        \n",
    "        if os.path.isdir(fruit_folder_path):  # checking if it's an valid path to a folder\n",
    "            for featureVectorFile in os.listdir(fruit_folder_path):\n",
    "\n",
    "                feature_file_path = os.path.join(fruit_folder_path, featureVectorFile) # creating complete path of the feature file\n",
    "                \n",
    "                if featureVectorFile.endswith('.npy'):  # checking if its a valid feature file\n",
    "                    labels.append(fruit_folder[:-2].strip())  # the folder name is the label (not taking the numbers at the end)\n",
    "\n",
    "                    featureVector = np.load(feature_file_path)\n",
    "                    features.append(featureVector)\n",
    "                    \n",
    "                    \n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030bdf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Features from img_ColourHist_LBP_Hist_Features/img_ColourHist_LBP_Hist_Features/Training: 100%|██████████| 160/160 [15:13<00:00,  5.71s/folder]\n",
      "Loading Features from img_ColourHist_LBP_Hist_Features/img_ColourHist_LBP_Hist_Features/Testing: 100%|██████████| 159/159 [05:14<00:00,  1.98s/folder]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (79921, 70)\n",
      "Testing Features Shape: (26668, 70)\n",
      "Number of Labels: 132\n",
      "Training Random Forest Classifier...\n",
      "Predicting test data...\n",
      "Random Forest Accuracy: 0.9910\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# loading the train and test feature data (LBP Histogram and Colour Histogram features)\n",
    "trainX, trainY = loadFeaturesAndLabels('img_ColourHist_LBP_Hist_Features/img_ColourHist_LBP_Hist_Features/Training')\n",
    "testX, testY = loadFeaturesAndLabels('img_ColourHist_LBP_Hist_Features/img_ColourHist_LBP_Hist_Features/Testing')\n",
    "\n",
    "# using StandardScaler to standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "trainX = scaler.fit_transform(trainX)\n",
    "testX = scaler.transform(testX)\n",
    "\n",
    "print(f\"Training Features Shape: {trainX.shape}\")\n",
    "print(f\"Testing Features Shape: {testX.shape}\")\n",
    "print(f\"Number of Labels: {len(np.unique(trainY))}\")\n",
    "\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, random_state=42)\n",
    "clf.fit(trainX, trainY)\n",
    "\n",
    "print(\"Predicting test data...\")\n",
    "y_pred = clf.predict(testX)\n",
    "\n",
    "accuracy = accuracy_score(testY, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b9f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest model successfully saved to random_forest_model.pkl\n",
      "Scaler successfully saved to scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the model to a .pkl file\n",
    "dump(clf, 'random_forest_model.pkl')\n",
    "print(f\"random forest model successfully saved to random_forest_model.pkl\")\n",
    "# Save the scaler to a .pkl file\n",
    "dump(scaler, 'scaler.pkl')\n",
    "print(f\"Scaler successfully saved to scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9ec142e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Loaded Model Accuracy: 0.9910\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "loaded_model = load('random_forest_model.pkl')\n",
    "print(\"Model loaded successfully.\")\n",
    "# Predicting with the loaded model\n",
    "y_pred_loaded = loaded_model.predict(testX)\n",
    "accuracy_loaded = accuracy_score(testY, y_pred_loaded)\n",
    "print(f\"Loaded Model Accuracy: {accuracy_loaded:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a9f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog, local_binary_pattern as lbp\n",
    "from PIL import Image\n",
    "\n",
    "# Load model and scaler\n",
    "clf = load('random_forest_model.pkl')  \n",
    "scaler = load('scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08482a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "# Function to load image data and convert to numpy array\n",
    "def convertImgToNumpyArr(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)  # creating reference variable img to access image data\n",
    "        img = img.resize((100, 100))  # resize image to 100x100 in case it is not\n",
    "        img = np.array(img)  # converting image data from JPG to numpy array\n",
    "        #img = img / 255.0  # normalizing RGB values (cv2 needs 0-255 range)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")  # error handling\n",
    "        return None\n",
    "\n",
    "# Function to compute colour histogram features for an image\n",
    "\n",
    "def computeColourHist(image, bins=20):\n",
    "\n",
    "    # conversion from RGB to HSV\n",
    "    hsvImg = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    hsvImg = hsvImg / 255.0  # normalizing\n",
    "    \n",
    "    # extracting histograms for Hue, Saturation, and Value\n",
    "    hueHist = np.histogram(hsvImg[:,:,0], bins=bins, range=(0, 1))[0]  \n",
    "    satHist = np.histogram(hsvImg[:,:,1], bins=bins, range=(0, 1))[0]  \n",
    "    valHist = np.histogram(hsvImg[:,:,2], bins=bins, range=(0, 1))[0]  \n",
    "    \n",
    "    # concatenating the histograms of Hue, Saturation, and Value and returning\n",
    "    return np.concatenate((hueHist, satHist, valHist))\n",
    "\n",
    "def computeLBP_Features(image):\n",
    "\n",
    "     # conversion to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # computing LBP features\n",
    "    lbpImg = lbp(gray, method=\"uniform\", P = 8, R = 1) \n",
    "    \n",
    "    bins = np.arange(0, 11) # number of bins for histogram (10)\n",
    "    lbpHist, _ = np.histogram(lbpImg.flatten(), bins=bins, range=(0, 10)) # computing histogram\n",
    "\n",
    "    return lbpHist / (np.sum(lbpHist) + 1e-6)\n",
    "\n",
    "def extract_features(image_path):\n",
    "    img = convertImgToNumpyArr(image_path)\n",
    "    ch_features = computeColourHist(img)\n",
    "    lbp_features = computeLBP_Features(img)\n",
    "    return np.concatenate([ch_features, lbp_features])  # Combine HOG + LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb5e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Apple\n"
     ]
    }
   ],
   "source": [
    "# Path to new image\n",
    "new_image_path = \"apple2.png\"  # Change this to your image path\n",
    "\n",
    "# Extract features (HOG + LBP only)\n",
    "features = extract_features(new_image_path).reshape(1, -1)  # Reshape to 2D array (1 sample, n features)\n",
    "\n",
    "# Scale features (use the same scaler!)\n",
    "scaled_features = scaler.transform(features)\n",
    "\n",
    "# Predict\n",
    "predicted_class = clf.predict(scaled_features)[0]\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
