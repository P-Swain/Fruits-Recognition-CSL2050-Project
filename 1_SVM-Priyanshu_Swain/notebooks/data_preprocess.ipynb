{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Libraries** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing req. libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import local_binary_pattern as lbp\n",
    "from skimage import exposure\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Convert Img to Numpy Array** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load image data and convert to numpy array\n",
    "def convertImgToNumpyArr(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)  # creating reference variable img to access image data\n",
    "        img = img.resize((100, 100))  # resize image to 100x100 in case it is not\n",
    "        img = np.array(img)  # converting image data from JPG to numpy array\n",
    "        #img = img / 255.0  # normalizing RGB values (cv2 needs 0-255 range)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")  # error handling\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Compute HOG Features** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute HOG features of an image\n",
    "def computeHOGFeatures(image):\n",
    "    \n",
    "    # conversion to grayscale\n",
    "    grayImg = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    grayImg = grayImg / 255.0  # normalizing\n",
    "\n",
    "    # computing HOG features\n",
    "    hogFeatures, hogImg = hog(grayImg, pixels_per_cell=(16, 16), orientations=9, cells_per_block=(2, 2), visualize=True) # 9 orientations, 16x16 pixels per cell, 2x2 cells per block\n",
    "\n",
    "    # increasing the contrast of the image\n",
    "    hogImg = exposure.rescale_intensity(hogImg, in_range=(0, 10))\n",
    "\n",
    "    return hogFeatures, hogImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Compute LBP Features** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_LBP_features(image):\n",
    "\n",
    "     # conversion to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # computing LBP features\n",
    "    lbpImg = lbp(gray, method=\"uniform\", P = 8, R = 1) \n",
    "    \n",
    "    bins = np.arange(0, 11) # number of bins for histogram (10)\n",
    "    lbpHist, _ = np.histogram(lbpImg.flatten(), bins=bins, range=(0, 10)) # computing histogram\n",
    "\n",
    "    return lbpHist / (np.sum(lbpHist) + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Compute Colour Histogram Features** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute colour histogram features for an image\n",
    "\n",
    "def computeColourHist(image, bins=20):\n",
    "\n",
    "    # conversion from RGB to HSV\n",
    "    hsvImg = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    hsvImg = hsvImg / 255.0  # normalizing\n",
    "    \n",
    "    # extracting histograms for Hue, Saturation, and Value\n",
    "    hueHist = np.histogram(hsvImg[:,:,0], bins=bins, range=(0, 1))[0]  \n",
    "    satHist = np.histogram(hsvImg[:,:,1], bins=bins, range=(0, 1))[0]  \n",
    "    valHist = np.histogram(hsvImg[:,:,2], bins=bins, range=(0, 1))[0]  \n",
    "    \n",
    "    # concatenating the histograms of Hue, Saturation, and Value and returning\n",
    "    return np.concatenate((hueHist, satHist, valHist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extracting Features** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features and save them as numpy arrays\n",
    "def saveImgFeaturesAsNumpyArr(src_path, save_path, featuresDescriptors = ['shape', 'colour', 'texture']):\n",
    "    print(f\"Original Image Folder: {src_path}\")\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)  # creating the save folder if it doesn't exist\n",
    "    print(f\"Saving Image Features Folder: {save_path}\")\n",
    "    \n",
    "    # going through each fruit folder in the source path (train or test)\n",
    "    for fruit_folder in os.listdir(src_path):\n",
    "        fruit_folder_path = os.path.join(src_path, fruit_folder)\n",
    "        \n",
    "        if os.path.isdir(fruit_folder_path):  # checking if the path actually points to a folder\n",
    "            print(f\"Currently Processing Fruit Images of: {fruit_folder}\")\n",
    "            \n",
    "            # going through each image file in the current folder\n",
    "            for img in os.listdir(fruit_folder_path):\n",
    "                img_path = os.path.join(fruit_folder_path, img)\n",
    "                \n",
    "                if img.endswith('.jpg'):  # checking if the file is an jpg image\n",
    "                    img_as_numpy_arr = convertImgToNumpyArr(img_path)\n",
    "                    if img_as_numpy_arr is None:  # handling image processing error\n",
    "                        print(f\"Error processing image {img_path}\")\n",
    "                    else:\n",
    "                        # computing the feature vector (HOG, Colour Histogram, etc.)\n",
    "\n",
    "                        featureMap = {}\n",
    "\n",
    "                        if('shape' in featuresDescriptors):\n",
    "                            hogFeatures, _ = computeHOGFeatures(img_as_numpy_arr)\n",
    "                            featureMap['shape'] = hogFeatures\n",
    "                            # print(\"HOG features shape:\", hogFeatures.shape)\n",
    "\n",
    "                        if('colour' in featuresDescriptors):\n",
    "                            colourHistFeatures = computeColourHist(img_as_numpy_arr)\n",
    "                            featureMap['colour'] = colourHistFeatures\n",
    "                            # print(\"Colour Histogram features shape:\", colourHistFeatures.shape)\n",
    "\n",
    "                        if('texture' in featuresDescriptors):\n",
    "                            lbpFeatures = extract_LBP_features(img_as_numpy_arr)\n",
    "                            featureMap['texture'] = lbpFeatures\n",
    "                            # print(\"LBP features shape:\", lbpFeatures.shape)\n",
    "\n",
    "                        featureVector = np.concatenate([featureMap[feature.lower()] for feature in featuresDescriptors if feature.lower() in featureMap])\n",
    "\n",
    "                        featureVector = featureVector.astype(np.float32) # converting to float32 for saving storage space\n",
    "                        # print(\"Feature vector length:\", len(featureVector))\n",
    "                        \n",
    "                        # creating the respective save path for each feature vector\n",
    "                        subfolder_path = os.path.relpath(fruit_folder_path, src_path)\n",
    "                        save_file_name = f\"{os.path.splitext(img)[0]}.npy\"  # saving file with .npy extension\n",
    "                        img_save_path = os.path.join(save_path, subfolder_path, save_file_name)\n",
    "                        \n",
    "                        # creating the save folder if it doesn't exist\n",
    "                        os.makedirs(os.path.dirname(img_save_path), exist_ok=True)\n",
    "                        np.save(img_save_path, featureVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image Conversion to Features** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Training Images\n",
      "Original Image Folder: ../../data/fruits-360/Training\n",
      "Saving Image Features Folder: ../features/img_Features/Training\n",
      "Currently Processing Fruit Images of: Blackberrie 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 1.11333033e-03 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 4.59037821e-03 2.22666067e-03 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.28885430e-01\n 4.33340218e-01 4.33340218e-01 4.33340218e-01 4.33340218e-01\n 4.33340218e-01 1.69895207e-01 1.16650127e-01 4.43950676e-02\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 5.55960007e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 5.55960007e-04 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 6.43610817e-02 3.36544266e-01\n 3.36544266e-01 3.36544266e-01 3.36544266e-01 2.88376379e-01\n 8.48399958e-02 5.82511797e-02 2.21694150e-02 5.99443423e-02\n 9.93018411e-02 5.40457867e-02 3.36544266e-01 3.36544266e-01\n 3.36544266e-01 2.92414024e-01 3.10863345e-02 7.70184549e-02\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 6.75251153e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 7.28064712e-02 1.20608824e-01\n 6.56422752e-02 3.72430011e-01 3.72430011e-01 3.72430011e-01\n 3.55156673e-01 3.77564626e-02 9.35441394e-02 3.71388122e-03\n 0.00000000e+00 3.81979684e-03 8.02668804e-02 3.72430011e-01\n 3.72430011e-01 3.72430011e-01 2.88487147e-02 1.72155931e-03\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 5.75077879e-03 0.00000000e+00\n 5.91478439e-03 1.24289671e-01 3.97332139e-01 3.97332139e-01\n 3.97332139e-01 4.46709432e-02 2.66575751e-03 3.97332139e-01\n 3.97332139e-01 1.12079751e-01 0.00000000e+00 1.86343293e-01\n 0.00000000e+00 2.21804421e-03 1.16901196e-03 3.81870788e-01\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 5.14037423e-01 5.14037423e-01\n 2.34648718e-01 0.00000000e+00 3.90125910e-01 0.00000000e+00\n 4.64366870e-03 2.44742834e-03 5.14037423e-01 3.28356985e-03\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.49374931e-03\n 7.24574902e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 4.19404487e-02 2.50455844e-01 2.56397775e-01\n 2.23208051e-01 2.56397775e-01 1.87918450e-01 5.52853899e-02\n 3.79589738e-02 1.44465442e-02 2.56397775e-01 2.56397775e-01\n 2.56397775e-01 2.56397775e-01 1.17003497e-01 2.96344194e-02\n 4.70581239e-02 9.84913061e-02 2.29094383e-01 2.56397775e-01\n 2.56397775e-01 2.38496444e-01 1.21125434e-01 2.54920933e-01\n 1.35432463e-01 8.19284342e-02 1.50569208e-01 2.37741771e-01\n 4.24013446e-02 2.53208176e-01 2.64418038e-01 2.25660949e-01\n 2.64418038e-01 1.89983541e-01 5.58929372e-02 3.83761161e-02\n 1.46053015e-02 3.94915786e-02 6.54204602e-02 3.56055860e-02\n 2.53925872e-01 2.64418038e-01 2.64418038e-01 1.92643558e-01\n 2.04798047e-02 5.07400740e-02 2.64418038e-01 2.64418038e-01\n 2.41117351e-01 1.22456517e-01 2.57722333e-01 1.36920770e-01\n 8.28287696e-02 1.52223857e-01 2.40354385e-01 1.06730205e-01\n 5.84522030e-02 8.82190536e-02 8.37189752e-02 1.53308596e-01\n 4.76593876e-02 6.41300663e-02 5.33589121e-02 5.12852433e-02\n 5.01161911e-02 8.30208467e-02 4.51847309e-02 2.96058950e-01\n 2.96058950e-01 2.96058950e-01 2.44471397e-01 2.59895867e-02\n 6.43909243e-02 2.55644283e-03 0.00000000e+00 2.62934964e-03\n 5.52515492e-02 2.87297207e-01 2.96058950e-01 2.96058950e-01\n 1.98579560e-02 1.18503196e-03 1.35444354e-01 7.41778851e-02\n 1.11953057e-01 1.06242301e-01 1.94553957e-01 6.04814258e-02\n 8.13832918e-02 6.77143213e-02 6.50827632e-02 1.91905373e-01\n 4.85848894e-02 5.83202284e-02 8.76423043e-02 1.10112258e-01\n 2.96058950e-01 2.96058950e-01 2.00151982e-01 1.31644874e-01\n 2.11907443e-03 0.00000000e+00 2.17950800e-03 4.57988513e-02\n 2.38145034e-01 2.66947447e-01 2.66947447e-01 1.64605624e-02\n 9.82291057e-04 2.66947447e-01 1.56644861e-01 4.12996817e-02\n 0.00000000e+00 6.86646662e-02 0.00000000e+00 8.17315522e-04\n 4.30763110e-04 1.40713571e-01 1.59073289e-01 4.02727554e-02\n 4.83425263e-02 7.26480420e-02 9.12737291e-02 2.66947447e-01\n 2.66947447e-01 1.65909029e-01 1.09122443e-01 2.66947447e-01\n 2.66947447e-01 2.66947447e-01 2.64335643e-01 2.66947447e-01\n 1.13511906e-01 1.55808115e-01 1.47362937e-01 1.94280426e-01\n 3.43812835e-01 1.51261331e-01 3.98803051e-02 0.00000000e+00\n 6.63048171e-02 0.00000000e+00 7.89226237e-04 4.15958757e-04\n 1.35877564e-01 5.58067261e-04 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 2.90963392e-01 3.43812835e-01\n 3.06665308e-01 2.55251026e-01 3.43812835e-01 1.09610758e-01\n 1.50453343e-01 1.42298406e-01 1.87603448e-01 1.30215693e-03\n 4.15958757e-04 1.38179104e-01 3.43812835e-01 3.43812835e-01\n 9.10656877e-02 1.25134569e-02 1.17135292e-02 0.00000000e+00\n 2.40548493e-01 2.40548493e-01 2.40548493e-01 2.40548493e-01\n 1.07879731e-01 2.73235697e-02 4.33885986e-02 9.08110947e-02\n 2.11229930e-01 2.40548493e-01 2.40548493e-01 2.19898832e-01\n 1.11680246e-01 2.35042563e-01 1.24871633e-01 7.55397718e-02\n 1.38828036e-01 2.19203007e-01 2.40548493e-01 2.10429720e-01\n 1.03020300e-01 2.40548493e-01 2.40548493e-01 1.01396749e-01\n 2.06763434e-01 1.54685463e-01 2.40548493e-01 2.58852971e-02\n 3.10724752e-02 2.07274456e-02 2.08182226e-02 1.08588716e-01\n 3.08893700e-02 2.65527055e-02 1.95440529e-02 3.67674939e-02\n 2.89833554e-01 2.89833554e-01 2.89833554e-01 2.40708379e-01\n 2.89833554e-01 2.69140243e-01 1.62813539e-01 2.89833554e-01\n 2.89833554e-01 2.09795733e-01 1.14897397e-01 1.73409027e-01\n 1.64563384e-01 2.89833554e-01 9.36823474e-02 1.26058169e-01\n 1.04885698e-01 1.00809562e-01 5.57914954e-02 6.69716035e-02\n 4.46745958e-02 4.48702507e-02 2.34045096e-01 6.65769506e-02\n 5.72299843e-02 4.21239876e-02 7.92462786e-02 7.01405961e-02\n 2.90781096e-03 3.22585887e-02 2.59232681e-02 6.86376375e-02\n 1.86779068e-02 2.56227919e-02 1.62260098e-02 1.11958261e-02\n 2.55982009e-01 1.40191920e-01 2.11584814e-01 2.00791813e-01\n 2.93914799e-01 1.14306402e-01 1.53809722e-01 1.27976157e-01\n 1.23002664e-01 2.93914799e-01 9.18226355e-02 1.10221864e-01\n 1.65638895e-01 2.08105809e-01 2.93914799e-01 2.93914799e-01\n 2.93914799e-01 2.48801211e-01 8.55819632e-02 3.54796201e-03\n 3.93602778e-02 3.16302441e-02 8.37481301e-02 2.27898253e-02\n 3.12636184e-02 1.97981461e-02 1.36605737e-02 2.93914799e-01\n 1.11287551e-01 1.44163555e-01 8.56137407e-02 4.93219937e-02\n 4.96173071e-02 3.38059219e-02 4.57660093e-02 1.49518030e-01\n 1.42658553e-01 3.61170190e-02 4.33540721e-02 6.51515073e-02\n 8.18552140e-02 2.69902431e-01 2.69902431e-01 1.48788914e-01\n 9.78621233e-02 2.69902431e-01 2.69902431e-01 2.69902431e-01\n 2.37058909e-01 2.69902431e-01 1.01798638e-01 1.39730312e-01\n 1.32156590e-01 1.74232674e-01 1.31298621e-01 4.37732435e-02\n 5.67045131e-02 3.36748459e-02 1.94000464e-02 1.95162033e-02\n 1.32970385e-02 1.80013547e-02 5.88106134e-02 2.69902431e-01\n 8.64881746e-02 2.69902431e-01 2.69902431e-01 1.96772854e-01\n 2.21150218e-02 1.86456188e-02 1.41738435e-01 2.21187164e-01\n 2.35738657e-01 2.94501717e-01 2.48460356e-01 2.06804484e-01\n 3.12281438e-01 8.88066807e-02 1.21897359e-01 1.15290226e-01\n 1.51996389e-01 1.05500807e-03 3.37009953e-04 1.11952766e-01\n 3.12281438e-01 3.12281438e-01 7.37814569e-02 1.01384078e-02\n 9.49030605e-03 0.00000000e+00 2.96509826e-01 7.54502008e-02\n 2.97103388e-01 3.12281438e-01 1.71659899e-01 1.92926125e-02\n 1.62659889e-02 1.23649198e-01 1.92958356e-01 1.05500807e-03\n 0.00000000e+00 0.00000000e+00 9.35348197e-02 1.12017814e-01\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 2.74218549e-01 2.22451362e-01 1.08905748e-01 2.68913065e-01\n 2.74218549e-01 1.07189445e-01 2.18575625e-01 1.63522491e-01\n 2.74218549e-01 2.73640986e-02 3.28476150e-02 2.19115841e-02\n 2.20075471e-02 1.14792282e-01 3.26540492e-02 2.80696354e-02\n 2.06605853e-02 3.88679845e-02 1.39699746e-02 2.68928154e-03\n 5.50708720e-03 2.73402416e-02 2.36814654e-01 2.74218549e-01\n 2.74218549e-01 2.74218549e-01 2.18656411e-01 4.57087850e-02\n 2.71147227e-02 7.94499422e-02 1.04691494e-01 2.74218549e-01\n 2.74218549e-01 1.66675114e-01 7.73147347e-02 1.67683279e-02\n 4.23090509e-02 5.07873998e-02 3.38786357e-02 3.40270091e-02\n 1.77486297e-01 5.04881178e-02 4.33999179e-02 3.19444017e-02\n 6.00958051e-02 5.31905809e-02 2.20511605e-03 2.44630523e-02\n 1.96587108e-02 5.20508239e-02 1.41642468e-02 1.94308469e-02\n 1.23048695e-02 8.49026853e-03 7.06727214e-02 4.19234779e-02\n 1.22841673e-01 1.61868945e-01 5.03205276e-01 5.03205276e-01\n 2.57705032e-01 1.19540318e-01 2.59263808e-02 4.15177647e-02\n 3.53626293e-02 1.17265053e-01 1.07525255e-01 5.03205276e-01\n 1.20579262e-01 6.01729015e-02 9.24551997e-02 3.70069958e-02\n 4.64773554e-02 1.92680660e-03 2.13755510e-02 1.71775692e-02\n 4.54814480e-02 1.23765659e-02 1.69784642e-02 1.07518622e-02\n 7.41870498e-03 1.81283044e-01 6.04373964e-02 7.82915057e-02\n 4.64946129e-02 2.67855018e-02 2.69458789e-02 1.83591237e-02\n 2.48543385e-02 8.11993829e-02 3.62777746e-02 3.08994837e-02\n 1.02464937e-01 9.39544069e-02 4.26004208e-01 1.05360857e-01\n 5.25784317e-02 8.07863554e-02 3.23363134e-02 1.58647445e-01\n 4.26004208e-01 4.26004208e-01 3.24228352e-01 4.26004208e-01\n 1.85067588e-01 5.81177250e-02 1.01641377e-02 6.02254988e-02\n 1.68776379e-01 5.62678379e-02 7.28901973e-02 4.32869630e-02\n 2.49375778e-02 2.50868905e-02 1.70925330e-02 2.31396448e-02\n 7.55974609e-02 3.12826161e-01 1.11175280e-01 3.12826161e-01\n 3.12826161e-01 2.52939516e-01 2.84275133e-02 2.39678071e-02\n 1.82196124e-01 2.84322625e-01 1.47702404e-01 3.12826161e-01\n 3.12826161e-01 3.01859932e-01 3.12826161e-01 1.72299829e-01\n 5.41082000e-02 9.46291673e-03 5.60705590e-02 6.63891881e-02\n 1.45796043e-01 0.00000000e+00 0.00000000e+00 1.77662423e-03\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 3.73865845e-01 1.76964373e-01 3.73865845e-01 3.73865845e-01\n 3.73865845e-01 4.52497811e-02 3.81509987e-02 2.90012518e-01\n 3.73865845e-01 2.47446447e-03 0.00000000e+00 0.00000000e+00\n 2.19380870e-01 2.62731736e-01 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 1.05675660e-01 2.32072322e-01\n 0.00000000e+00 0.00000000e+00 2.82795953e-03 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 2.13661329e-02 4.11307454e-03 8.42271802e-03 4.18150536e-02\n 3.55723580e-01 3.55723580e-01 3.55723580e-01 3.55723580e-01\n 3.34420217e-01 6.99085005e-02 4.14701375e-02 1.21513322e-01\n 1.60118572e-01 3.55723580e-01 3.55723580e-01 2.54918333e-01\n 1.18247666e-01 2.56460254e-02 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.10109728e-04\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 7.29367568e-02 4.32665172e-02 1.26776967e-01 1.67054496e-01\n 5.17082474e-01 5.17082474e-01 2.65960739e-01 1.23369851e-01\n 2.67569452e-02 4.28478067e-02 3.64954885e-02 1.21021696e-01\n 1.10969879e-01 5.17082474e-01 1.24442078e-01 6.21005700e-02\n 9.54170475e-02 3.81925332e-02 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 8.45201597e-04 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.81733877e-04\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 3.75960495e-02 3.20223204e-02 1.06188345e-01 9.73685562e-02\n 4.38585156e-01 1.09189498e-01 5.44890458e-02 8.37219992e-02\n 3.35113621e-02 1.64412434e-01 4.38585156e-01 4.38585156e-01\n 3.36010280e-01 4.38585156e-01 1.91792641e-01 6.02296280e-02\n 1.05334858e-02 6.24139948e-02 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 2.47202403e-04 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.47202403e-04\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 2.90704208e-01 4.11459977e-01 4.11459977e-01 4.11459977e-01\n 4.11459977e-01 3.39116249e-01 1.06494417e-01 1.86246780e-02\n 1.10356683e-01 1.30665553e-01 2.86952155e-01 0.00000000e+00\n 0.00000000e+00 3.49670774e-03 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 4.37088467e-04 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 7.06563934e-01 7.06563934e-01 0.00000000e+00 0.00000000e+00\n 3.91767049e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 6.93200000e+03 1.05000000e+03 1.22600000e+03 3.49000000e+02\n 4.00000000e+00 1.20000000e+01 0.00000000e+00 5.30000000e+01\n 0.00000000e+00 2.00000000e+00 3.00000000e+00 1.04000000e+02\n 1.42000000e+02 1.23000000e+02 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 7.20900000e+03 2.52000000e+02 2.61000000e+02 2.79000000e+02\n 2.63000000e+02 3.33000000e+02 1.77000000e+02 3.92000000e+02\n 3.71000000e+02 1.62000000e+02 1.06000000e+02 7.30000000e+01\n 5.70000000e+01 4.80000000e+01 1.50000000e+01 2.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 8.07000000e+02 1.04600000e+03 2.39000000e+02 1.76000000e+02\n 1.60000000e+02 1.27000000e+02 7.90000000e+01 6.70000000e+01\n 5.90000000e+01 5.20000000e+01 7.00000000e+01 3.50000000e+01\n 2.00000000e+01 1.40000000e+01 2.40000000e+01 2.00000000e+01\n 2.70000000e+01 2.10000000e+01 2.70000000e+01 6.93000000e+03\n 9.20000000e-03 1.57000000e-02 1.35000000e-02 5.41000000e-02\n 6.45000000e-02 1.23600000e-01 2.61000000e-02 4.63000000e-02\n 6.15200000e-01 3.18000000e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Training Images to Features:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Training Images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43msaveImgFeaturesAsNumpyArr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../features/img_Features/Training\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Testing Images to Features:\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Testing Images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 47\u001b[0m, in \u001b[0;36msaveImgFeaturesAsNumpyArr\u001b[0;34m(src_path, save_path, featuresDescriptors)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m     46\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m---> 47\u001b[0m featureVector \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatureVector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m featureVector \u001b[38;5;241m=\u001b[39m featureVector\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;66;03m# converting to float32 for saving storage space\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# print(\"Feature vector length:\", len(featureVector))\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# creating the respective save path for each feature vector\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PRML/lib/python3.11/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PRML/lib/python3.11/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    903\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    904\u001b[0m             (\n\u001b[1;32m    905\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    914\u001b[0m         )\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PRML/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:894\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PRML/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PRML/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:930\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \n\u001b[1;32m    900\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    929\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 930\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PRML/lib/python3.11/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PRML/lib/python3.11/site-packages/sklearn/utils/validation.py:1093\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1087\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1088\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1089\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1092\u001b[0m             )\n\u001b[0;32m-> 1093\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1099\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 1.11333033e-03 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 4.59037821e-03 2.22666067e-03 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.28885430e-01\n 4.33340218e-01 4.33340218e-01 4.33340218e-01 4.33340218e-01\n 4.33340218e-01 1.69895207e-01 1.16650127e-01 4.43950676e-02\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 5.55960007e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 5.55960007e-04 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 6.43610817e-02 3.36544266e-01\n 3.36544266e-01 3.36544266e-01 3.36544266e-01 2.88376379e-01\n 8.48399958e-02 5.82511797e-02 2.21694150e-02 5.99443423e-02\n 9.93018411e-02 5.40457867e-02 3.36544266e-01 3.36544266e-01\n 3.36544266e-01 2.92414024e-01 3.10863345e-02 7.70184549e-02\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 6.75251153e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 7.28064712e-02 1.20608824e-01\n 6.56422752e-02 3.72430011e-01 3.72430011e-01 3.72430011e-01\n 3.55156673e-01 3.77564626e-02 9.35441394e-02 3.71388122e-03\n 0.00000000e+00 3.81979684e-03 8.02668804e-02 3.72430011e-01\n 3.72430011e-01 3.72430011e-01 2.88487147e-02 1.72155931e-03\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 5.75077879e-03 0.00000000e+00\n 5.91478439e-03 1.24289671e-01 3.97332139e-01 3.97332139e-01\n 3.97332139e-01 4.46709432e-02 2.66575751e-03 3.97332139e-01\n 3.97332139e-01 1.12079751e-01 0.00000000e+00 1.86343293e-01\n 0.00000000e+00 2.21804421e-03 1.16901196e-03 3.81870788e-01\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 5.14037423e-01 5.14037423e-01\n 2.34648718e-01 0.00000000e+00 3.90125910e-01 0.00000000e+00\n 4.64366870e-03 2.44742834e-03 5.14037423e-01 3.28356985e-03\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.49374931e-03\n 7.24574902e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 4.19404487e-02 2.50455844e-01 2.56397775e-01\n 2.23208051e-01 2.56397775e-01 1.87918450e-01 5.52853899e-02\n 3.79589738e-02 1.44465442e-02 2.56397775e-01 2.56397775e-01\n 2.56397775e-01 2.56397775e-01 1.17003497e-01 2.96344194e-02\n 4.70581239e-02 9.84913061e-02 2.29094383e-01 2.56397775e-01\n 2.56397775e-01 2.38496444e-01 1.21125434e-01 2.54920933e-01\n 1.35432463e-01 8.19284342e-02 1.50569208e-01 2.37741771e-01\n 4.24013446e-02 2.53208176e-01 2.64418038e-01 2.25660949e-01\n 2.64418038e-01 1.89983541e-01 5.58929372e-02 3.83761161e-02\n 1.46053015e-02 3.94915786e-02 6.54204602e-02 3.56055860e-02\n 2.53925872e-01 2.64418038e-01 2.64418038e-01 1.92643558e-01\n 2.04798047e-02 5.07400740e-02 2.64418038e-01 2.64418038e-01\n 2.41117351e-01 1.22456517e-01 2.57722333e-01 1.36920770e-01\n 8.28287696e-02 1.52223857e-01 2.40354385e-01 1.06730205e-01\n 5.84522030e-02 8.82190536e-02 8.37189752e-02 1.53308596e-01\n 4.76593876e-02 6.41300663e-02 5.33589121e-02 5.12852433e-02\n 5.01161911e-02 8.30208467e-02 4.51847309e-02 2.96058950e-01\n 2.96058950e-01 2.96058950e-01 2.44471397e-01 2.59895867e-02\n 6.43909243e-02 2.55644283e-03 0.00000000e+00 2.62934964e-03\n 5.52515492e-02 2.87297207e-01 2.96058950e-01 2.96058950e-01\n 1.98579560e-02 1.18503196e-03 1.35444354e-01 7.41778851e-02\n 1.11953057e-01 1.06242301e-01 1.94553957e-01 6.04814258e-02\n 8.13832918e-02 6.77143213e-02 6.50827632e-02 1.91905373e-01\n 4.85848894e-02 5.83202284e-02 8.76423043e-02 1.10112258e-01\n 2.96058950e-01 2.96058950e-01 2.00151982e-01 1.31644874e-01\n 2.11907443e-03 0.00000000e+00 2.17950800e-03 4.57988513e-02\n 2.38145034e-01 2.66947447e-01 2.66947447e-01 1.64605624e-02\n 9.82291057e-04 2.66947447e-01 1.56644861e-01 4.12996817e-02\n 0.00000000e+00 6.86646662e-02 0.00000000e+00 8.17315522e-04\n 4.30763110e-04 1.40713571e-01 1.59073289e-01 4.02727554e-02\n 4.83425263e-02 7.26480420e-02 9.12737291e-02 2.66947447e-01\n 2.66947447e-01 1.65909029e-01 1.09122443e-01 2.66947447e-01\n 2.66947447e-01 2.66947447e-01 2.64335643e-01 2.66947447e-01\n 1.13511906e-01 1.55808115e-01 1.47362937e-01 1.94280426e-01\n 3.43812835e-01 1.51261331e-01 3.98803051e-02 0.00000000e+00\n 6.63048171e-02 0.00000000e+00 7.89226237e-04 4.15958757e-04\n 1.35877564e-01 5.58067261e-04 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 2.90963392e-01 3.43812835e-01\n 3.06665308e-01 2.55251026e-01 3.43812835e-01 1.09610758e-01\n 1.50453343e-01 1.42298406e-01 1.87603448e-01 1.30215693e-03\n 4.15958757e-04 1.38179104e-01 3.43812835e-01 3.43812835e-01\n 9.10656877e-02 1.25134569e-02 1.17135292e-02 0.00000000e+00\n 2.40548493e-01 2.40548493e-01 2.40548493e-01 2.40548493e-01\n 1.07879731e-01 2.73235697e-02 4.33885986e-02 9.08110947e-02\n 2.11229930e-01 2.40548493e-01 2.40548493e-01 2.19898832e-01\n 1.11680246e-01 2.35042563e-01 1.24871633e-01 7.55397718e-02\n 1.38828036e-01 2.19203007e-01 2.40548493e-01 2.10429720e-01\n 1.03020300e-01 2.40548493e-01 2.40548493e-01 1.01396749e-01\n 2.06763434e-01 1.54685463e-01 2.40548493e-01 2.58852971e-02\n 3.10724752e-02 2.07274456e-02 2.08182226e-02 1.08588716e-01\n 3.08893700e-02 2.65527055e-02 1.95440529e-02 3.67674939e-02\n 2.89833554e-01 2.89833554e-01 2.89833554e-01 2.40708379e-01\n 2.89833554e-01 2.69140243e-01 1.62813539e-01 2.89833554e-01\n 2.89833554e-01 2.09795733e-01 1.14897397e-01 1.73409027e-01\n 1.64563384e-01 2.89833554e-01 9.36823474e-02 1.26058169e-01\n 1.04885698e-01 1.00809562e-01 5.57914954e-02 6.69716035e-02\n 4.46745958e-02 4.48702507e-02 2.34045096e-01 6.65769506e-02\n 5.72299843e-02 4.21239876e-02 7.92462786e-02 7.01405961e-02\n 2.90781096e-03 3.22585887e-02 2.59232681e-02 6.86376375e-02\n 1.86779068e-02 2.56227919e-02 1.62260098e-02 1.11958261e-02\n 2.55982009e-01 1.40191920e-01 2.11584814e-01 2.00791813e-01\n 2.93914799e-01 1.14306402e-01 1.53809722e-01 1.27976157e-01\n 1.23002664e-01 2.93914799e-01 9.18226355e-02 1.10221864e-01\n 1.65638895e-01 2.08105809e-01 2.93914799e-01 2.93914799e-01\n 2.93914799e-01 2.48801211e-01 8.55819632e-02 3.54796201e-03\n 3.93602778e-02 3.16302441e-02 8.37481301e-02 2.27898253e-02\n 3.12636184e-02 1.97981461e-02 1.36605737e-02 2.93914799e-01\n 1.11287551e-01 1.44163555e-01 8.56137407e-02 4.93219937e-02\n 4.96173071e-02 3.38059219e-02 4.57660093e-02 1.49518030e-01\n 1.42658553e-01 3.61170190e-02 4.33540721e-02 6.51515073e-02\n 8.18552140e-02 2.69902431e-01 2.69902431e-01 1.48788914e-01\n 9.78621233e-02 2.69902431e-01 2.69902431e-01 2.69902431e-01\n 2.37058909e-01 2.69902431e-01 1.01798638e-01 1.39730312e-01\n 1.32156590e-01 1.74232674e-01 1.31298621e-01 4.37732435e-02\n 5.67045131e-02 3.36748459e-02 1.94000464e-02 1.95162033e-02\n 1.32970385e-02 1.80013547e-02 5.88106134e-02 2.69902431e-01\n 8.64881746e-02 2.69902431e-01 2.69902431e-01 1.96772854e-01\n 2.21150218e-02 1.86456188e-02 1.41738435e-01 2.21187164e-01\n 2.35738657e-01 2.94501717e-01 2.48460356e-01 2.06804484e-01\n 3.12281438e-01 8.88066807e-02 1.21897359e-01 1.15290226e-01\n 1.51996389e-01 1.05500807e-03 3.37009953e-04 1.11952766e-01\n 3.12281438e-01 3.12281438e-01 7.37814569e-02 1.01384078e-02\n 9.49030605e-03 0.00000000e+00 2.96509826e-01 7.54502008e-02\n 2.97103388e-01 3.12281438e-01 1.71659899e-01 1.92926125e-02\n 1.62659889e-02 1.23649198e-01 1.92958356e-01 1.05500807e-03\n 0.00000000e+00 0.00000000e+00 9.35348197e-02 1.12017814e-01\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 2.74218549e-01 2.22451362e-01 1.08905748e-01 2.68913065e-01\n 2.74218549e-01 1.07189445e-01 2.18575625e-01 1.63522491e-01\n 2.74218549e-01 2.73640986e-02 3.28476150e-02 2.19115841e-02\n 2.20075471e-02 1.14792282e-01 3.26540492e-02 2.80696354e-02\n 2.06605853e-02 3.88679845e-02 1.39699746e-02 2.68928154e-03\n 5.50708720e-03 2.73402416e-02 2.36814654e-01 2.74218549e-01\n 2.74218549e-01 2.74218549e-01 2.18656411e-01 4.57087850e-02\n 2.71147227e-02 7.94499422e-02 1.04691494e-01 2.74218549e-01\n 2.74218549e-01 1.66675114e-01 7.73147347e-02 1.67683279e-02\n 4.23090509e-02 5.07873998e-02 3.38786357e-02 3.40270091e-02\n 1.77486297e-01 5.04881178e-02 4.33999179e-02 3.19444017e-02\n 6.00958051e-02 5.31905809e-02 2.20511605e-03 2.44630523e-02\n 1.96587108e-02 5.20508239e-02 1.41642468e-02 1.94308469e-02\n 1.23048695e-02 8.49026853e-03 7.06727214e-02 4.19234779e-02\n 1.22841673e-01 1.61868945e-01 5.03205276e-01 5.03205276e-01\n 2.57705032e-01 1.19540318e-01 2.59263808e-02 4.15177647e-02\n 3.53626293e-02 1.17265053e-01 1.07525255e-01 5.03205276e-01\n 1.20579262e-01 6.01729015e-02 9.24551997e-02 3.70069958e-02\n 4.64773554e-02 1.92680660e-03 2.13755510e-02 1.71775692e-02\n 4.54814480e-02 1.23765659e-02 1.69784642e-02 1.07518622e-02\n 7.41870498e-03 1.81283044e-01 6.04373964e-02 7.82915057e-02\n 4.64946129e-02 2.67855018e-02 2.69458789e-02 1.83591237e-02\n 2.48543385e-02 8.11993829e-02 3.62777746e-02 3.08994837e-02\n 1.02464937e-01 9.39544069e-02 4.26004208e-01 1.05360857e-01\n 5.25784317e-02 8.07863554e-02 3.23363134e-02 1.58647445e-01\n 4.26004208e-01 4.26004208e-01 3.24228352e-01 4.26004208e-01\n 1.85067588e-01 5.81177250e-02 1.01641377e-02 6.02254988e-02\n 1.68776379e-01 5.62678379e-02 7.28901973e-02 4.32869630e-02\n 2.49375778e-02 2.50868905e-02 1.70925330e-02 2.31396448e-02\n 7.55974609e-02 3.12826161e-01 1.11175280e-01 3.12826161e-01\n 3.12826161e-01 2.52939516e-01 2.84275133e-02 2.39678071e-02\n 1.82196124e-01 2.84322625e-01 1.47702404e-01 3.12826161e-01\n 3.12826161e-01 3.01859932e-01 3.12826161e-01 1.72299829e-01\n 5.41082000e-02 9.46291673e-03 5.60705590e-02 6.63891881e-02\n 1.45796043e-01 0.00000000e+00 0.00000000e+00 1.77662423e-03\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 3.73865845e-01 1.76964373e-01 3.73865845e-01 3.73865845e-01\n 3.73865845e-01 4.52497811e-02 3.81509987e-02 2.90012518e-01\n 3.73865845e-01 2.47446447e-03 0.00000000e+00 0.00000000e+00\n 2.19380870e-01 2.62731736e-01 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 1.05675660e-01 2.32072322e-01\n 0.00000000e+00 0.00000000e+00 2.82795953e-03 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 2.13661329e-02 4.11307454e-03 8.42271802e-03 4.18150536e-02\n 3.55723580e-01 3.55723580e-01 3.55723580e-01 3.55723580e-01\n 3.34420217e-01 6.99085005e-02 4.14701375e-02 1.21513322e-01\n 1.60118572e-01 3.55723580e-01 3.55723580e-01 2.54918333e-01\n 1.18247666e-01 2.56460254e-02 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.10109728e-04\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 7.29367568e-02 4.32665172e-02 1.26776967e-01 1.67054496e-01\n 5.17082474e-01 5.17082474e-01 2.65960739e-01 1.23369851e-01\n 2.67569452e-02 4.28478067e-02 3.64954885e-02 1.21021696e-01\n 1.10969879e-01 5.17082474e-01 1.24442078e-01 6.21005700e-02\n 9.54170475e-02 3.81925332e-02 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 8.45201597e-04 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.81733877e-04\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 3.75960495e-02 3.20223204e-02 1.06188345e-01 9.73685562e-02\n 4.38585156e-01 1.09189498e-01 5.44890458e-02 8.37219992e-02\n 3.35113621e-02 1.64412434e-01 4.38585156e-01 4.38585156e-01\n 3.36010280e-01 4.38585156e-01 1.91792641e-01 6.02296280e-02\n 1.05334858e-02 6.24139948e-02 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 2.47202403e-04 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.47202403e-04\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 2.90704208e-01 4.11459977e-01 4.11459977e-01 4.11459977e-01\n 4.11459977e-01 3.39116249e-01 1.06494417e-01 1.86246780e-02\n 1.10356683e-01 1.30665553e-01 2.86952155e-01 0.00000000e+00\n 0.00000000e+00 3.49670774e-03 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 4.37088467e-04 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 7.06563934e-01 7.06563934e-01 0.00000000e+00 0.00000000e+00\n 3.91767049e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 6.93200000e+03 1.05000000e+03 1.22600000e+03 3.49000000e+02\n 4.00000000e+00 1.20000000e+01 0.00000000e+00 5.30000000e+01\n 0.00000000e+00 2.00000000e+00 3.00000000e+00 1.04000000e+02\n 1.42000000e+02 1.23000000e+02 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 7.20900000e+03 2.52000000e+02 2.61000000e+02 2.79000000e+02\n 2.63000000e+02 3.33000000e+02 1.77000000e+02 3.92000000e+02\n 3.71000000e+02 1.62000000e+02 1.06000000e+02 7.30000000e+01\n 5.70000000e+01 4.80000000e+01 1.50000000e+01 2.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 8.07000000e+02 1.04600000e+03 2.39000000e+02 1.76000000e+02\n 1.60000000e+02 1.27000000e+02 7.90000000e+01 6.70000000e+01\n 5.90000000e+01 5.20000000e+01 7.00000000e+01 3.50000000e+01\n 2.00000000e+01 1.40000000e+01 2.40000000e+01 2.00000000e+01\n 2.70000000e+01 2.10000000e+01 2.70000000e+01 6.93000000e+03\n 9.20000000e-03 1.57000000e-02 1.35000000e-02 5.41000000e-02\n 6.45000000e-02 1.23600000e-01 2.61000000e-02 4.63000000e-02\n 6.15200000e-01 3.18000000e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Paths to the train and test folders\n",
    "train_path = '../../data/fruits-360/Training'\n",
    "test_path = '../../data/fruits-360/Test'\n",
    "\n",
    "# Training Images to Features:\n",
    "print(\"Processing Training Images\")\n",
    "saveImgFeaturesAsNumpyArr(train_path, '../features/img_Features/Training')\n",
    "\n",
    "# Testing Images to Features:\n",
    "print(\"Processing Testing Images\")\n",
    "saveImgFeaturesAsNumpyArr(test_path, '../features/img_Features/Testing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PRML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
